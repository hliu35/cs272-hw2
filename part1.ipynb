{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE272 HW2 Recommendation System \n",
    "\n",
    "Author: Anthony Liu ([e-mail](mailto:hliu35@ucsc.edu))\n",
    "\n",
    "Date: 05/20/2021\n",
    "\n",
    "Please read README.md before running."
   ]
  },
  {
   "source": [
    "## 1. Data Selection and Preprocessing\n",
    "\n",
    "The default dataset used is the video game [review dataset](http://jmcauley.ucsd.edu/data/amazon/) from Amazon. Please note that we are using the FULL .json dataset instead of the 5-category subset.\n",
    "\n",
    "The code below divides the dataset by a training-to-testing ratio of 80%:20%."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/ry/Documents/recommender\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import utils as UT\n",
    "\n",
    "# working directory\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Video_Games_5.json\n"
     ]
    }
   ],
   "source": [
    "# shell script $ ls data\n",
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "231780\n"
     ]
    }
   ],
   "source": [
    "f = open(\"data/Video_Games_5.json\")\n",
    "data_list = []\n",
    "for l in f.readlines():\n",
    "    data_list.append(json.loads(l))\n",
    "\n",
    "print(len(data_list))\n",
    "f.close()\n",
    "\n",
    "# sort the data based on reviewerID (uid)\n",
    "data_list.sort(key=lambda r: (r[\"reviewerID\"], r[\"asin\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['reviewerID', 'asin', 'reviewerName', 'helpful', 'reviewText', 'overall', 'summary', 'unixReviewTime', 'reviewTime']\n"
     ]
    }
   ],
   "source": [
    "uids, pids, ratings, reviews, titles, unixtimestamps, helpfulness = [], [], [], [], [], [], []\n",
    "col_titles = [x for x in data_list[0].keys()]\n",
    "print(col_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "User count: 24303\nProduct count: 10672\n"
     ]
    }
   ],
   "source": [
    "# convert to Pandas-friendly format (column-wise)\n",
    "product_names = dict() # storing for recommendation\n",
    "uid_set = set()\n",
    "pid_set = set()\n",
    "\n",
    "for row in data_list:\n",
    "    uids.append(row[\"reviewerID\"])\n",
    "    pids.append(row[\"asin\"])\n",
    "    ratings.append(row[\"overall\"])\n",
    "    reviews.append(row[\"reviewText\"])\n",
    "    titles.append(row[\"summary\"])\n",
    "    unixtimestamps.append(\"unixReviewTime\")\n",
    "    h = UT.sigmoid(row[\"helpful\"][1]-row[\"helpful\"][0]) # using sigmoid instead of difference\n",
    "    helpfulness.append(h)\n",
    "\n",
    "    product_names[row[\"asin\"]] = row[\"summary\"]\n",
    "    uid_set.add(row[\"reviewerID\"]) # IMPORTANT: ALL USER ID IN DATASET\n",
    "    pid_set.add(row[\"asin\"]) # IMPORTANT: ALL PRODUCT ID IN DATASET\n",
    "\n",
    "# generate a reverse map from uid/pid to ndarray index\n",
    "print(\"User count:\",len(uid_set))\n",
    "print(\"Product count:\",len(pid_set))\n",
    "\n",
    "uid_idx = dict()\n",
    "pid_idx = dict()\n",
    "\n",
    "for i, uid in enumerate(list(uid_set)):\n",
    "    uid_idx[uid] = i\n",
    "\n",
    "for j, pid in enumerate(list(pid_set)):\n",
    "    pid_idx[pid] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"indices.pickle\", \"wb\") as f:\n",
    "    pickle.dump([uid_idx, pid_idx, uid_set, pid_set], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"user-id\":uids,\n",
    "        \"product-id\":pids, \n",
    "        #\"helpfulness\":helpfulness, \n",
    "        \"rating\":ratings, \n",
    "        #\"review\":reviews, \n",
    "        #\"title\":titles, \n",
    "        #\"timestamp\":unixtimestamps\n",
    "}\n",
    "DF = pd.DataFrame(data)\n",
    "DF.to_pickle(\"DF.pickle\")"
   ]
  },
  {
   "source": [
    "#### *continues in* `part2a.ipynb`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}