{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Part 3. Recommendation\n",
    "\n",
    "For the baseline, our model selects the top 10 predicted ratings and their respective items. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "\n",
    "import numpy as np \n",
    "import torch\n",
    "\n",
    "import utils as UT \n",
    "\n",
    "#np.random.seed(40) # fixed random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained model\n",
    "model = torch.load(\"checkpoint.pt\")\n",
    "with open(\"user_ratings.pickle\", \"rb\") as f:\n",
    "    user_ratings = pickle.load(f)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prepare training data\n",
    "m, n = user_ratings.shape\n",
    "k = 10\n",
    "#bitmask = np.random.rand(m, n) > 0.8\n",
    "bitmask = UT.generate_bitmask(user_ratings)\n",
    "train = user_ratings.copy()\n",
    "train[bitmask] = 0\n",
    "test = user_ratings - train\n",
    "test_size = np.count_nonzero(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorized test \n",
    "model.eval()\n",
    "\n",
    "user_embeddings = model.U.weight.transpose(0,1).unsqueeze(1)\n",
    "item_embeddings = model.V.weight.transpose(0,1).unsqueeze(2)\n",
    "product = torch.matmul(item_embeddings, user_embeddings).transpose(0,2)\n",
    "pred_torch = model.A_pred(product).squeeze()"
   ]
  },
  {
   "source": [
    "optional: to assure the correctness of matrix multiplications\n",
    "``` python\n",
    "# backup: per element test\n",
    "predictions = np.zeros((m, n))\n",
    "test_idx = np.nonzero(user_ratings - train)\n",
    "X, Y = test_idx\n",
    "\n",
    "print(\"total test data:\",len(X))\n",
    "\n",
    "for i in range(len(X)):\n",
    "    x, y = X[i], Y[i]\n",
    "    xl = torch.LongTensor([x])\n",
    "    yl = torch.LongTensor([y])\n",
    "\n",
    "    pred = model(xl, yl).item()\n",
    "    #pred = pred / 4 * 5 # HACKS!!!!\n",
    "    predictions[x, y] = pred\n",
    "\n",
    "#print(torch.sum(pred_torch - torch.from_numpy(predictions))) # difference between vectorized and element-wise tests\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "rmse: 1.48\nmae: 0.85\n"
     ]
    }
   ],
   "source": [
    "# compute basic errors using the test set\n",
    "predictions = pred_torch.detach().numpy()\n",
    "pred_copy = predictions.copy()\n",
    "pred_copy[test==0] = 0 # delete those cannot be tested (not in test data)\n",
    "\n",
    "rmse = np.sqrt(np.sum(np.square(test-pred_copy)) / test_size) # rmse\n",
    "mae = np.sum(test-pred_copy) / test_size # mae\n",
    "\n",
    "print(\"rmse: %.2f\"%rmse)\n",
    "print(\"mae: %.2f\"%mae)"
   ]
  },
  {
   "source": [
    "# avoids training data\n",
    "predictions[train!=0] = 0\n",
    "\n",
    "# compute different scores\n",
    "# methodology=0: using also predictions on user-item pairs beyond this dataset\n",
    "# methodology=1: using only predictions that have their corresponding ground truths\n",
    "prec, rec, F, cr, ndcg = UT.compute_scores(prediction=predictions.copy(), \n",
    "                                            ground_truth=test.copy(), \n",
    "                                            K=10,\n",
    "                                            w=-2,\n",
    "                                            methodology=1)\n",
    "print(\"Precision: %.2f %%\\nRecall: %.2f %%\\nF: %.2f\\nConversion Rate: %.2f %%\\nNDCG: %.2f\"%(prec*100, rec*100, F, cr*100, ndcg))"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Precision: 95.05 %\nRecall: 93.04 %\nF: 0.94\nConversion Rate: 99.81 %\nNDCG: 0.95\n"
     ]
    }
   ]
  }
 ]
}